---
output: pdf_document
---
## Analysis and plots of montreal data.

```{r, echo=FALSE, include=FALSE}
req.packages <- c("data.table", "ggplot2", "reshape2", "grid")
sapply(req.packages, require, character.only = T)
```

### Required packages: `r req.packages`.

Source data:

```{r, echo=FALSE}
src.dt <- fread("../input/merged.o", header = F, sep=" ", colClasses = c("integer","integer","integer","integer"))
setnames(src.dt, c("user_id", "location_id", "login", "logout"))
setkey(src.dt, login, logout, user_id, location_id)
src.dt
```

```{r}
max_hours <- 24
min_logins <- 2
```

Trim data:

1. remove sessions exceeding `r max_hours` hours
2. eliminate users that have fewer than `r min_logins` logins
3. eliminate locations that have fewer than `r min_logins` logins
4. recursively apply steps 2-3 until no users / locations eliminated

```{r, echo=FALSE}
censor.dt <- src.dt[(logout - login) <= max_hours*60*60, ]
invalid.users <- censor.dt[,.N, by=user_id ][N < min_logins, user_id]
while(length(invalid.users) > 0) {
  censor.dt <- censor.dt[!user_id %in% invalid.users]
  invalid.locs <- censor.dt[,.N, by=location_id ][N < min_logins, location_id]
  censor.dt <- censor.dt[!location_id %in% invalid.locs]
  invalid.users <- censor.dt[,.N, by=user_id ][N < min_logins, user_id]
}
censor.dt
```

Removed `r dim(src.dt)[1] - dim(censor.dt)[1]` rows, or `r (dim(src.dt)[1] - dim(censor.dt)[1])/dim(src.dt)[1]` reduction.

Relabel source data:

1. re-assign user ids from 1, ordered by first appearance
2. re-assign location ids from 1, ordered by first appearance
3. TODO split entries that cross days (~ 3% of data; of crossing entries, most look like late PM->early AM sessions, aka bar / club visits)
4. convert login / logout times to `log(in|out)_day` and `log(in|out)_time`
5. mark data as the empirical source: set `run_id = 0`, `sample_id = 0`, `target = FALSE`.

```{r, echo=FALSE}
source("munging.R")
breakoutDays(censor.dt[,
  user_id := .GRP, by=user_id
][,
  location_id := .GRP, by=location_id
])
setkey(censor.dt, login_day, login_time, logout_day, logout_time, user_id, location_id)
censor.dt
```

When generating our synthetic data, we assume locations exist before and after they join the service.  So the synthetic population may make visits to these locations outside of time when the service is operating.  We trim that activity from the synthetic data according the time that locations are active in the observed data.

```{r, echo=FALSE}
## TODO switch to log(in|out) day
limits.dt <- censor.dt[,list(first=min(login), last=max(logout)), keyby=location_id]
limits.dt
save(censor.dt, limits.dt, file = "../input/censored.Rdata")
```

The locations have different patterns of activity, reflecting their different hours of operation.

```{r, echo=FALSE}
hours.dt <- censor.dt[,
  list(login_day, login_time, logout_day, logout_time, logout_time_adj=0),
  keyby=list(location_id, user_id)
]
hours.dt[ login_day != logout_day,
   logout_time_adj := logout_time + 24*60*60
]
hours.dt <- hours.dt[,
  list(open=min(login_time), close=max(logout_time, logout_time_adj)),
  by=list(login_day, location_id)
]
p <- ggplot(hours.dt[,
  list(med_open = median(open), med_close=median(close)), by=location_id
][, open_id:=.GRP, by=list(med_open, location_id)])+aes(x=open_id, y=med_open/3600) + geom_point() + geom_hline(yintercept=1:23, color="red") + theme_bw()
# bad.list <- with(src.dt[(logout - login) > max_real_duration,],
#   list(bad_users = unique(user_id), bad_locs = unique(location_id), bad_entries = length(user_id) )
# )
# 
# duration.censored.dt <- src.dt[(logout - login) <= max_real_duration,]
# 
# eliminated.users <- setdiff(bad.list$bad_users, unique(duration.censored.dt$user_id))
# eliminated.locs <- setdiff(bad.list$bad_locs, unique(duration.censored.dt$location_id))
# warning("eliminated ", length(eliminated.users)," users with only >24 hour sessions: ", paste(eliminated.users, collapse=" "))
# 
# user.location.count.dt <- duration.censored.dt[,
# 	list(location_count = length(unique(location_id))),
# 	by="user_id"
# ]
# valid.users <- user.location.count.dt[location_count > 1,user_id]
# 
# user_and_duration.censored.dt <- duration.censored.dt[user_id %in% valid.users,]
# 
# locs.dt <- user_and_duration.censored.dt[,
# 	list(
# 		unique_users = length(unique(user_id)),
# 		total_login_time = sum(logout - login)),
# 	by="location_id"
# ] # unique users per location
# 
# min_total_login <- 60*60 # 1 hour
# 
# invalid.locs <- locs.dt[(unique_users == 1) | (total_login_time < min_total_login), location_id] # locations with only one user, or total log in time < 1 hour
# 
# loc_user_duration.censored.dt <- user_and_duration.censored.dt[!(location_id %in% invalid.locs),]
# loc_user_duration.censored.dt[,user_id := .GRP, by=user_id]
# loc_user_duration.censored.dt[,location_id := .GRP, by=location_id]
# 
# loc_view.dt <- loc_user_duration.censored.dt[,
#   list(
#     unique_users = length(unique(user_id)),
#     total_login_time = sum(logout - login),
#     mean_login = mean(logout - login),
#     sd_login = sd(logout - login)
#   ),
#   by="location_id"]
# 
# user_view.dt <- loc_user_duration.censored.dt[,
# 	list(
# 		unique_locs = length(unique(location_id)),
# 		total_login_time = sum(logout - login),
# 		mean_login = mean(logout - login),
# 		sd_login = sd(logout - login),
#     first = min(login),
#     last = max(logout)
# 	),
# 	by="user_id"
# ]
# 
# user_view.dt[, login_proportion := total_login_time / (last-first) ]
# 
# ggplot(user_view.dt) + theme_bw() +
#   aes(x=user_id, ymin=first, ymax=last, alpha=login_proportion) + geom_linerange() + coord_flip()
# 
# 
# break_categorization <- function(dt, target, output) {
# 	bks <- hist(dt[[target]], plot = F)$breaks
# 	lbls <- paste(head(bks, -1), tail(bks, -1), sep="-")
# 	dt[[output]] <- sapply(dt[[target]], function(n) factor(lbls[which.max(n <= bks)-1], levels=lbls))
# 	dt
# }
# 
# #loc_count_breaks <- hist(user_view.dt$unique_locs, plot = F)$breaks
# 
# #loc_count_cats <- paste(head(loc_count_breaks, -1), tail(loc_count_breaks, -1), sep="-")
# 
# #user_view.dt[,loc_count_cat := sapply(unique_locs, function(n) which.max(n <= loc_count_breaks)-1)]
# #user_view.dt$loc_count_cat <- factor(loc_count_cats[user_view.dt$loc_count_cat], levels=loc_count_cats)
# 
# user_view.dt <- break_categorization(user_view.dt, "unique_locs", "loc_count_cat")
# 
# # sum(loc_user_duration.censored.dt[,length(unique(location_id)),by="user_id"]$V1 == 1) == 0 # => no more user ids to censor
# 
# total_login_duration <- sum(as.numeric(loc_view.dt$total_login_time))
# loc_view.dt[,proportion := total_login_time/total_login_duration]
# 
# nets.dt <- loc_user_duration.censored.dt[, list(first=min(login),last=max(logout)), by=c("user_id","location_id")]
# 
# melt_nets.dt <- melt(nets.dt, id.vars = c("user_id", "location_id"))
# melt_nets.dt$inc <- ifelse(melt_nets.dt$variable == "first", 1, -1)
# setkey(melt_nets.dt, value, user_id, location_id)
# 
# melt_nets.dt[,net_users := cumsum(inc), by="location_id"]
# melt_nets.dt[,net_locs  := cumsum(inc), by="user_id"]
# 
# acc_loc_time <- melt_nets.dt[,
# 	list(ave_concurrent_locs = 
# 	  sum(diff(value)*head(net_locs,-1)) /
# 	  sum(diff(value)*(head(net_locs,-1)>0)),
# 	  unique_locs = sum(abs(inc))/2
# 	), # exclude time intervals w/ no presence
# 	by="user_id"]
# acc_loc_time <- break_categorization(acc_loc_time, "ave_concurrent_locs","con_locs_cat")
# acc_loc_time <- break_categorization(acc_loc_time, "unique_locs","unique_locs_cat")
# 
# ggplot(acc_loc_time[ave_concurrent_locs >= 2,]) + theme_bw() +
# 	aes(x=ave_concurrent_locs, fill=unique_locs_cat) + geom_bar() +
# 	scale_x_log10() #+ scale_y_log10()
# #sample(loc_view.dt$location_id, 5, F, loc_view.dt$proportion)
# 
# p.loc <- ggplot(loc_view.dt) + theme_bw()
# p.user <- ggplot(user_view.dt) + theme_bw()
# 
# p.user + theme(panel.margin = unit(0.5, "lines")) +
# 	aes(fill=loc_count_cat, x=total_login_time/60) +
# 	facet_grid(loc_count_cat ~ ., scales="free_y", shrink=T, drop=F) +
# 	geom_bar() + scale_x_log10(name="total login time per individual, in minutes") +
# 	ylab("number of individuals") +
# 	scale_fill_discrete(name="locations per individual", drop=F) +
# 	scale_y_continuous(breaks=function(lims) c(head(lims,1), tail(lims, 1)), expand=c(0,0))
# 
# p + aes(x=(logout - login)) + geom_bar() + geom_vline(x=150, color="red") + scale_x_log10()
# 
# #####
# p + aes(x=unique_users) + geom_bar() + scale_x_log10()
# p + aes(x=total_login_time) + geom_bar() + scale_x_log10()
# 
# src.dt[,length(unique(user_id)),by="location_id"] # unique users per location
# src.dt[,length(unique(location_id)),by="user_id"] # unique locations by user
# 
# regular_users <- src.dt[,list(regular = length(location_id) > 1), by="user_id"] # users w/ more than one login
# regular_users <- regular_users[regular == T, user_id, keyby="user_id"]$user_id
```